{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix C. Fundamentals of Mathematical Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical inference involves learning something about a population given the availability of a sample from the population. By \"learning\" Wooldridge mean several things such as estimation or hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let Y be a random sample variable representing a population with a probability density function f(y;&theta;), which depdens on the singe parameter &theta. The probability density function of Y is assumed to be known except for the value &theta; different values of &theta; imply different population distributions and therefore we are interested in the value of this &theta; If we can obtain certain kinds of samples from the population , then we can learn something about &theta;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest sampling scheme to deal with is random sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Sampling. If Y1,Y2,...,Yn are independent random variables with a common probability density function f(y:&theta;), then [Y1,Y2,...,Yn] is said to be a random sample from f(y;&theta;) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When [Y1,Y2,...,Yn] is a random sample from the density f(y;&theta;) we also say that Yi are independent, identically distributed or (i.i.d) random variables from f(y:&theta;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C.2. Finite Sample Properties of estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are concerned with finite sample properties of estimators. The term \"finite\" sample comes from the fact that properties holf for a sample og any size no matter how large or small. Sometimes these are called small sample properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-2a Estimators and Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a random sample {Y1, Y2,..,Yn} drawn from a population distribution that depends on an unknown parameter &theta; an estimator of &theta; is a rule that assigns each possible outcome of the sample a value of &theta;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example of an estimator, let {Y1,Y2,...,Yn} be a random sample from a population with mean &mu;. A natural estimator of &mu; is the average of the random sample: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\vec{Y} & = n^{-1} \\sum_{i=1}^n Y_i \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\vec{Y} \\\\\n",
    "\\end{align}\n",
    " is called the sample average\n",
    "The distribution of an estimator is often called sampling distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-2b Unbiadsedness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An estimator, W of &theta;, is an unbiased estimator if E(W)=&theta; for all possible values of E(W)=&theta;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an estimator is unbiased, then its probability distribution has an expected value equal to the parameter it is supposed to be estimating. \n",
    "Unbiadseness does not mean that the estimate we get with any particular is equal to &theta;, or even very close to &theta;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an estimator that is not unbiased, we define its bias as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If W is a biased estimator of &theta; its bias is defined: Bias(W):=E(W)-&theta;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some estimators can be shown to be unbiased quite generally. The sample average is an unbiased estimator of the population mean &mu;, regardless of the underlying population distribution.Refer to Wooldridge page 677 for a formal proof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For hypotheses testing, we will need to estimate the variance &sigma;^2 from a population with mean &mu;. Letting {Y1,..,Yn} denote the random sample from the population with E(Y)=&mu; and Var(Y)= &sigma;^2, define the estimator as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\ S^2 & = 1/(n-1) \\sum_{i=1}^n (Y_i - \\vec{y})^2 \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is usually called the sample variance. It can be shown that S^2 is an unbiased for sigma;^2: E(S^2)= &sigma;^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The division by n-1, rather than n, accounts for the fact that the mean &mu; is estimated rathern than known."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-2d The sampling variance of estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbiadseness only ensures that the sampling distribution of an estimator has a mean value equal for the parameter it is supposed to be estimating. This is fine but we also need to know how spread out the distribution of an estimator is. An estimator can be equal to &theta;on average, but it can also be very far away with large probability. Refer to wooldrige page 679 for a visual example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance of an estimator is often called its sampling variance and provides a single measure of the dispersion in the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write expression C.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, if {Yi:i+1,2,..,n} is a random sample from a population with mean &mu; and variance &sigma;^2, Then the sample average has the same mean as the population, but its sampling variance equals the population variance,&sigma;^2 , divided by the sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important implication of the previsous expression C.6 is that it can be made very close to zero by increasing the sample size n. This is a key feature of an estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-2e Efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relative efficiency. If W1 and W2 are two unbiased estimators of &theta;, W1 is efficient relative to W2 when Var(W1) &le; Var(W2) for all &theta; with strict inequality for at least one value of &theta;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C.3. Asymptotic or Large Sample Properties of Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Asymptotic analysis involves approximating the features of the sampling distribution of an estimator. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### C-3a Consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let Wn be an estimator of &theta; based on a sample Y1,Y2,..., Yn of size n. Then Wn is a consistent estimator of &theta; if for every &epsilon; &ge;0, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "P(\\left| W_n - \\theta  \\right| \\ge \\epsilon) \\rightarrow 0  as n \\rightarrow \\infty\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If Wn is not consistent for &theta; then we say it is inconsistent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Unlike unbiadsedness, which is a feature of an estimator for a given sample size, consistency involves the behavior of the sampling distribuion of the estimator as the sample size n gets large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If an estimator is not consistent then it does not help us to learn about &theta; even with an unlimited amount of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "An example of a consistent estimator is the average of a random sample drawn from a population with mean &mu; and variance &sigma;^2. We have already shown that the sample average is unbiased for &mu;. Given expression C.6 we notice that Var(Yhat) tends to cero as n increases so this estimator is also consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The conclusion that the YHAT is consistent for &mu; holds even if Var(Yhat) does not exist. This classic result is known as the law of large numbers (LLN) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-3b Asymptotic normality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consistency informs us that the distribution of the estimator is collapsing around the parameter as the sample size gets large, it does not however tells us anything about the shape of the distribution for a given sample size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For constructing interval estimators and testing hypotheses we need a way to approximate the distribution of our estimators. Most econometric estimators have distributions that are well approximated by a normal distribution for large samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asimptotic normality property means that the cummulative distribution function of a given sequence of random variables gets closer and closer to the CDF of the standard normal distribution as the sample size n gets large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The central limit theorem (CLT), one of the most powerful results in probability and statistics, states that the average from a random sample for any population (with finite variance), when standarized, has an asymptotic standard normal distribution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Central Limit Theorem (CLT). Let {Y1,Y2,..,Yn} be a random sample with mean &mu; and variance &sigma;^2. Then,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align} \n",
    "\\ Z_{n} = \\frac{(\\vec{Y} - \\mu)}{(\\sigma/\\sqrt{n})}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "has an asymptotic standard normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Most estimators envountered in statistics and econometrics can be written as functions of sample averages, in which case we can apply the law of large numbers and the central limit theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By replacing &sigma; with its consistent estimator S_n in the previous equation we obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align} \n",
    "\\frac{(\\vec{Y} - \\mu)}{(s_n/\\sqrt{n})}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "which also has an approximate standard normal distribution for large n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C-4. General approaches to parameter estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods of moments, maximum likelihood, Least Squares. Refer to Wooldridge for more details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C-5. Interval Estimation and Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a population with a N(&mu;,1) distribution and let {Y1,Y2,..,Yn} be a random sample from this population. the sample average Yhat has a normal distribution wiht mean &mu; and variance 1/n. Therefore we can standarize Yhat to have:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "P(-1.96 \\leq \\frac{(\\vec{Y} - \\mu)}{(1/\\sqrt{n})} \\ge 1.96) = 0.95\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is equivalent to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "P(\\vec{Y}-1.96/\\sqrt{n} \\leq \\mu \\ge \\vec{Y}-1.96/\\sqrt{n}) = 0.95\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous equation tells us that the probability that the random interval contains the population mean &mu; is 0.95 or 95%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "When we say that the previous equation is a 95% confidence interval for &mu; we mean that the random interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "[\\vec{Y}-1.96/\\sqrt{n},\\vec{Y}+1.96/\\sqrt{n}] \n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "contains &mu; with probability 0.95. In other words, before the random sample is drawn, there is a 95% chance that the interval contains &mu;. This is an interval estimator and it is random interval as the endpoints change with different samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-5b Confidence Intervals for the Mean from the a Normally Distributed Population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous equation is not very useful in practice given that it assumes that the variance is known to be unity. It is easy to extend it to the case where the standard deviation /mu; is known to be any value. In this case the 95% confidence interval is "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "[\\vec{y}-1.96 *\\sigma/\\sqrt{n},\\vec{y]}+1.96 * \\sigma/\\sqrt{n}] \n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore provided &sigma; is not known, a confidence interval for &mu; is readily computed. To allow for unknown &sigma; we first must use an estimate. Let"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\ s = (\\frac{1}{n-1} * \\sum_{i=1}^n (y_i - \\vec{y})^2 )^{1/2}\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denote the sample standard deviation. Thus we have obtained a confidence interval that depends entirely on the observed data by replacing &sigma; with its estimate s. However in this case the 95% level of confidence is no longer preserved becasuse s depends on the particular example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we rely on the t distribution. The t distribution arises from the fact that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\frac{(\\vec{Y} - \\mu)}{(S/\\sqrt{n})} \\sim t_{n-1}\n",
    "\\end{equation*} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where Yhat is the sample average and S is the sample standard deviation of the random sample {Y1,Y2,...,Yn}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wooldridge. Example C.2. Effect of Job training grants on worker's productivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We are analyzing scrap rates for firms that receive a job training grant in 1998. The scrap rates for 1987 and 1988 are printed in Wooldridge (Table C.3). We are interested in the change between the years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Change: -7 0 -1 0.05 0.29 0.2 -0.26 -1 -7.51 -0.5 -0.47 -0.5 0.16 1.67 -4 -2 1 -0.08 -2 -0.14\n",
      " Sample Average: -1.1545\n",
      " Sample Size: 20\n",
      " Standard Deviation: 2.400639\n",
      " Standard Error: 0.5367992\n",
      " 97.5% percentile (C) with n-1 degrees of freedom: 2.093024\n",
      " confidence interval: [ -2.278034 -0.03096631 ]"
     ]
    }
   ],
   "source": [
    "# Manually enter raw data from Wooldridge, Table C.3:\n",
    "SR87<-c(10,1,6,.45,1.25,1.3,1.06,3,8.18,1.67,.98,1,.45,\n",
    "                                      5.03,8,9,18,.28,7,3.97)\n",
    "SR88<-c(3,1,5,.5,1.54,1.5,.8,2,.67,1.17,.51,.5,.61,6.7,\n",
    "                                            4,7,19,.2,5,3.83)\n",
    "# Calculate Change (the parentheses just display the results):\n",
    "cat(\" Change:\",(Change <- SR88 - SR87))\n",
    "\n",
    "\n",
    "\n",
    "# Ingredients to CI formula\n",
    "cat(\"\\n Sample Average:\",(avgCh<- mean(Change)))\n",
    "cat(\"\\n Sample Size:\", n    <- length(Change))\n",
    "cat(\"\\n Standard Deviation:\",(sdCh <- sd(Change)))\n",
    "cat(\"\\n Standard Error:\",(se   <- sdCh/sqrt(n)))\n",
    "cat(\"\\n 97.5% percentile (C) with n-1 degrees of freedom:\",(c    <- qt(.975, n-1)))\n",
    "\n",
    "# Confidence intervall:\n",
    "cat(\"\\n confidence interval: [\",c( avgCh - c*se, avgCh + c*se ),\"]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "given the previous confidence interval we can conclude that with 95% confidence, the average change in scrap rates in the population is not zero and thus that job training has a positive impact on worker's productivity (via scrap reduction rates)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-5c A simple Rule of Thumb for a 95% Confidence Interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous confidence interval can be computed for any sample size and any confidence level. Given that the t distribution approaches the standard normal distribution as the degreess of freedom gets large, a rule of thumb for an approximate 95% confidence interval is "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "[\\vec{y}\\pm 2*se(\\vec{y})]\n",
    "\\end{equation*} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is we obtain yhat and its standard error and then compute yhat plus or minus twice its standard error to obtain the confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-5d Asymptotic Confidence Interval for NonnormalPopulations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some applications the population is clearly nonnormal. A leading case is the Bernouilli distribution where the random variable takes on only the values zero and one, in other cases the nonnormal population has no standard distribution. this does not matter provided the sample size is sufficiently large for the central limit theorem to give a good approximation for the distribution of the sample averata Yhat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For large n, an approximate 95% confidence interval is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "[\\vec{y}\\pm 1.96*se(\\vec{y})]\n",
    "\\end{equation*} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the value 1.96 is the 97.5th percentile in the standard normal distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wooldridge. Example C.3 Race Discrimination in Hiring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are looking into race discrimination using the dataset AUDIT.DTA The variable y represents the difference in hiring rates between black and white applicants with identical CV. After calculating the average, sample size, standard deviation and the standard error of the sample average, the following code calculates the value for the factor c as the 97.5 percentile of the standard normal distribution which is 1.96. Finally, the 95% and 99% CI are reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(foreign)\n",
    "audit <- read.dta(\"https://github.com/thousandoaks/Wooldridge/blob/master/audit.dta?raw=true\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>w</th><th scope=col>b</th><th scope=col>y</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><td>1</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><td>1</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><td>1</td><td>1</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " w & b & y\\\\\n",
       "\\hline\n",
       "\t 1 & 1 & 0\\\\\n",
       "\t 1 & 1 & 0\\\\\n",
       "\t 1 & 1 & 0\\\\\n",
       "\t 1 & 1 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "w | b | y | \n",
       "|---|---|---|---|\n",
       "| 1 | 1 | 0 | \n",
       "| 1 | 1 | 0 | \n",
       "| 1 | 1 | 0 | \n",
       "| 1 | 1 | 0 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  w b y\n",
       "1 1 1 0\n",
       "2 1 1 0\n",
       "3 1 1 0\n",
       "4 1 1 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# w =1 if the white person got the job offer from employee i, 0 otherwise\n",
    "# b=1 if the black person got the job offer from employee i, 0 otherwise\n",
    "# y=b-w\n",
    "head(audit,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of y is clearly not normal, it is discrete and takes only three values, nevertheless and approximate confidence interval for &theta;b - &theta;w can be obtained by using large sample methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the 241 observed data points, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average w: 0.3568465\n",
      "average b: 0.2240664\n",
      "average y: -0.1327801"
     ]
    }
   ],
   "source": [
    "cat(\"average w:\",(avgw<- mean(audit$w)))\n",
    "cat(\"\\naverage b:\",(avgb<- mean(audit$b)))\n",
    "cat(\"\\naverage y:\",(avgy<- mean(audit$y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that: $\\vec{b}$=.224 and  $\\vec{w}$=.357 we conclude that there is evidence of discrimination against blacks. We can learn much more however by computing a 95% confidence interval for &mu;."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -0.1936301 -0.07193011 ]"
     ]
    }
   ],
   "source": [
    "n   <- length(audit$y)\n",
    "sdy <- sd(audit$y)\n",
    "se  <- sdy/sqrt(n)\n",
    "c   <- qnorm(.975)\n",
    "\n",
    "# 95% Confidence intervall:\n",
    "cat(\"[\",avgy + c * c(-se,+se),\"]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And computing a 99% confidence interval for &mu;."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -0.2127505 -0.05280966 ]"
     ]
    }
   ],
   "source": [
    "# 99% Confidence intervall:\n",
    "cat(\"[\",avgy + qnorm(.995) * c(-se,+se),\"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither interval contains the value zero thus indicating that there is evidence of discrimination against black people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C-6. Hypotheses Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have reviewed how to evaluate point estimators and we have seen how to construct and interpret confidence intervals. Sometimes however we are interested in a yes/no answer. Devising methods for anwsering such questions, using a sample of data, is known as hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-6a Fundamentals of Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following Wooldridge we illustrate the concept with an election example. Suppose there are two candidates in an election, Candidares A and candidates B. Candidate A is reported to have received 42% of the popular vote, while Candidate B received 58%. These are supposed to represent the true percentages of the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Candidate A is convinced that more people mush have voted for him, so he would like to investigate whether the election was rigged. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to proceed is to set up a hypothesis test. Let &theta; denote the true proportion of the population voting for Candidate A. The hypothesis that the reported results are accurate can be stated as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "H_0:\\theta =.42\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of a null hypothesis. The null hypothesis is presumed to be true until the data strongly suggests otherwise. In the current example Candidate A must present fairly strong evidence against the null hypothesis in order to win a recount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The alternative Hypothesis in the election example is that the true proportion voting for Candidate A in the election is greater than .42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "H_1:\\theta \\gt .42\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In order to conclude that Ho is false and that H1 is true we must have evidence \"beyond reasonable doubt\" against H0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In hypotheses testing we can make two kinds of mistakes. First we can reject the null hypothesis when it is in fact true, this is called a Type I error. In the election example a Type I occurs if we reject Ho when the true proportion of people voting for Candiate A is in fact .42."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second kind of error is failing to reject Ho when it is actually false. This is called a Type II error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will never know with certainty whether an error was committed. However we can compute the probability of making either a Type I or a Type II error. Generally we define the significance level of a test as the probability of a Type I error, this is typically denoted by &alpha;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\alpha = P(Reject \\hspace{.1cm} H_o \\mid H_o)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is read: The probability of rejecting Ho given that Ho is true. If &alpha;=.5 then the researcher is willing to falsely reject Ho 5% of the time, in order to detect deviations from Ho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Once we have chosen the significance level, we would then like to minimize the probability of a Type II error or, conversely, maximize the power of a test against all relevant alternatives. The power of a test is just one minus the probability of a Type II error. Mathematically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\pi (\\theta) =1- P(Type II  \\mid \\theta)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where &theta; denotes the actual value of the parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-6b Testing hypotheses about the mean in a Normal Population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test a null hypothesis against an alternative, we need to choose a test statistic and a critical value. The choices for the statistic and critical value are based on convenience and on the desire to maximize power given a significance level for the test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Testing hypotheses about the mean &mu; from a normal population is straightforward. The null hypothesis is stated as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "H_0:\\mu = \\mu_0\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rejection rule we choose depends on the nature of the alternative hypothesis. If we are interested for instance in the value of &mu; only when &mu; is at least as large as &mu;0 then"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "H_1:\\mu \\gt \\mu_0\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively we should reject Ho in favor of H1 when the value of the sample average, yhat, is \"sufficiently\" greater than &mu;o. In order to determine when yhat is large enough for Ho to be rejected at the chosen significance level we use the following test statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\sqrt{n}*(\\vec{y}-\\mu_0)/s = (\\vec{y}-\\mu_0)/se(\\vec{y})\n",
    "\\end{equation*} \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where se(yhat)=s/SQRT(n) is the standard error of yhat. Given the sample of data, it is easy to obtain t. We work with t because, under the null hypothesis, the random variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "T=\\sqrt{n}*(\\vec{Y}-\\mu_0)/S \n",
    "\\end{equation*} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "has a tn-1 distribution. Now suppose we have settled on a 5% significance level. Then, the critical value c is chosen so that P(T>c|Ho)=0.5. That is, the probability of a Type I error is 5%. Once we have found c, the rejection rule is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "t \\gt c\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where c is the 100(1-&alpha;) percentile in a tn-1 distribution. This is an example of a one-tailed test because the rejection region is in one tail of the t distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Wooldridge. Example C.5 Race Discrimination in Hiring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Urgan Institute study of discrimination in hiring (see Example C.3) usig the data in AUDIT, we are primarily interested in testing Ho:&mu;=0 against Ho:&mu;<0 where &mu; is the difference in probaiblities that blacks and whites receive job offers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>w</th><th scope=col>b</th><th scope=col>y</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><td>1</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><td>1</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><td>1</td><td>1</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " w & b & y\\\\\n",
       "\\hline\n",
       "\t 1 & 1 & 0\\\\\n",
       "\t 1 & 1 & 0\\\\\n",
       "\t 1 & 1 & 0\\\\\n",
       "\t 1 & 1 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "w | b | y | \n",
       "|---|---|---|---|\n",
       "| 1 | 1 | 0 | \n",
       "| 1 | 1 | 0 | \n",
       "| 1 | 1 | 0 | \n",
       "| 1 | 1 | 0 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  w b y\n",
       "1 1 1 0\n",
       "2 1 1 0\n",
       "3 1 1 0\n",
       "4 1 1 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(foreign)\n",
    "audit <- read.dta(\"https://github.com/thousandoaks/Wooldridge/blob/master/audit.dta?raw=true\")\n",
    "head(audit,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the 241 paired comparisons in the data file AUDIT, we obtain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average y: -0.1327801\n",
      "Standard Error: 0.03104648"
     ]
    }
   ],
   "source": [
    "cat(\"\\nAverage y:\",(avgy<- mean(audit$y)))\n",
    "n   <- length(audit$y)\n",
    "sdy <- sd(audit$y)\n",
    "cat('\\nStandard Error:',se  <- sdy/sqrt(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the t statistic for testing Ho:&mu;=0 can be aproximated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t statistic aproximation -4.276816"
     ]
    }
   ],
   "source": [
    "cat('t statistic aproximation',(t <- avgy/se))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value is so far out in the left tail of the distribution that we reject Ho at any reasonable significance level. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the following table shows the .0.5 critical value for the one-side test is about -2.58 thus a t value of -4.28 is very strong evidence against Ho in favor of H1. Thus we conclude that there is discrimination in hiring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>alpha.one.tailed</th><th scope=col>CV</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.100   </td><td>1.285089</td></tr>\n",
       "\t<tr><td>0.050   </td><td>1.651227</td></tr>\n",
       "\t<tr><td>0.025   </td><td>1.969898</td></tr>\n",
       "\t<tr><td>0.010   </td><td>2.341985</td></tr>\n",
       "\t<tr><td>0.005   </td><td>2.596469</td></tr>\n",
       "\t<tr><td>0.001   </td><td>3.124536</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       " alpha.one.tailed & CV\\\\\n",
       "\\hline\n",
       "\t 0.100    & 1.285089\\\\\n",
       "\t 0.050    & 1.651227\\\\\n",
       "\t 0.025    & 1.969898\\\\\n",
       "\t 0.010    & 2.341985\\\\\n",
       "\t 0.005    & 2.596469\\\\\n",
       "\t 0.001    & 3.124536\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "alpha.one.tailed | CV | \n",
       "|---|---|---|---|---|---|\n",
       "| 0.100    | 1.285089 | \n",
       "| 0.050    | 1.651227 | \n",
       "| 0.025    | 1.969898 | \n",
       "| 0.010    | 2.341985 | \n",
       "| 0.005    | 2.596469 | \n",
       "| 0.001    | 3.124536 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     alpha.one.tailed CV      \n",
       "[1,] 0.100            1.285089\n",
       "[2,] 0.050            1.651227\n",
       "[3,] 0.025            1.969898\n",
       "[4,] 0.010            2.341985\n",
       "[5,] 0.005            2.596469\n",
       "[6,] 0.001            3.124536"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha.one.tailed = c(0.1, 0.05, 0.025, 0.01, 0.005, .001)\n",
    "CV <- qt(1 - alpha.one.tailed, n-1)\n",
    "cbind(alpha.one.tailed, CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-6d Computing and Using p-Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the p-value of a test provides a measure of how large is the significance level at which we could carry the significance test and still fail to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, small p-values are evidence against Ho, since they indicate that the outcome of the data occurs with small probability if Ho is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, a large p-value is weak evidence against Ho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wooldridge. Example C.6. Effect of Job training grants on worker's productivity (Revisited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider again the example C.2. From a policy perspective, there are two questions of interest. First, what is our best estimate of the mean change in scrap rates &mu; ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already obtained this for the 20 sample of firms understudy. The sample average of the change in scrap rates is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Sample Average: -1.1545"
     ]
    }
   ],
   "source": [
    "# Manually enter raw data from Wooldridge, Table C.3:\n",
    "SR87<-c(10,1,6,.45,1.25,1.3,1.06,3,8.18,1.67,.98,1,.45,\n",
    "                                      5.03,8,9,18,.28,7,3.97)\n",
    "SR88<-c(3,1,5,.5,1.54,1.5,.8,2,.67,1.17,.51,.5,.61,6.7,\n",
    "                                            4,7,19,.2,5,3.83)\n",
    "# Calculate Change (the parentheses just display the results):\n",
    "Change <- SR88 - SR87\n",
    "\n",
    "\n",
    "\n",
    "# Ingredients to CI formula\n",
    "cat(\"\\n Sample Average:\",(avgCh<- mean(Change)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relative to the initial average scrap rate in 1987, this represent a fall in the scrap rate of about 26.3% (-1.15/4.38 = -.263), which is a non trivial effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we would also like to know whether the sample provides strong evidence for an effect in the population of manufacturing firms that could have received grants. The null Hypothesis is Ho:&mu;=0 and we test this against H1:&mu;<0, where &mu; is the average change in scrap rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Change: -7 0 -1 0.05 0.29 0.2 -0.26 -1 -7.51 -0.5 -0.47 -0.5 0.16 1.67 -4 -2 1 -0.08 -2 -0.14\n",
      " Sample Average: -1.1545\n",
      " Sample Size: 20\n",
      " Standard Deviation: 2.400639\n",
      " Standard Error: 0.5367992\n",
      " 97.5% percentile (C) with n-1 degrees of freedom: 2.093024\n",
      " confidence interval: [ -2.278034 -0.03096631 ]"
     ]
    }
   ],
   "source": [
    "# Manually enter raw data from Wooldridge, Table C.3:\n",
    "SR87<-c(10,1,6,.45,1.25,1.3,1.06,3,8.18,1.67,.98,1,.45,\n",
    "                                      5.03,8,9,18,.28,7,3.97)\n",
    "SR88<-c(3,1,5,.5,1.54,1.5,.8,2,.67,1.17,.51,.5,.61,6.7,\n",
    "                                            4,7,19,.2,5,3.83)\n",
    "# Calculate Change (the parentheses just display the results):\n",
    "cat(\" Change:\",(Change <- SR88 - SR87))\n",
    "\n",
    "\n",
    "\n",
    "# Ingredients to CI formula\n",
    "cat(\"\\n Sample Average:\",(avgCh<- mean(Change)))\n",
    "cat(\"\\n Sample Size:\", n    <- length(Change))\n",
    "cat(\"\\n Standard Deviation:\",(sdCh <- sd(Change)))\n",
    "cat(\"\\n Standard Error:\",(se   <- sdCh/sqrt(n)))\n",
    "cat(\"\\n 97.5% percentile (C) with n-1 degrees of freedom:\",(c    <- qt(.975, n-1)))\n",
    "\n",
    "# Confidence intervall:\n",
    "cat(\"\\n confidence interval: [\",c( avgCh - c*se, avgCh + c*se ),\"]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic -2.150711\n",
      "p-value 0.02229063"
     ]
    }
   ],
   "source": [
    "cat('t-statistic',(t <- avgCh/se))\n",
    "# p value\n",
    "cat('\\np-value',(p <- pt(t,n-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This small p-value gives reasonable evidence against Ho. This is certainly enough evidence to reject the null hypothesis that the train grants had no effect at the 2.5% significance level (or higher, for instance 5%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wooldridge. Example C.7 Race Discrimination in Hiring (revisited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the matched pairs data from the Urban Institute in the AUDIT data file (n=241), we obtained the following t statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(foreign)\n",
    "audit <- read.dta(\"https://github.com/thousandoaks/Wooldridge/blob/master/audit.dta?raw=true\")\n",
    "avgy<- mean(audit$y)\n",
    "n   <- length(audit$y)\n",
    "sdy <- sd(audit$y)\n",
    "se  <- sdy/sqrt(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t statistic aproximation -4.276816"
     ]
    }
   ],
   "source": [
    "cat('t statistic aproximation',(t <- avgy/se))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "p-value 1.369271e-05"
     ]
    }
   ],
   "source": [
    "cat('\\np-value',(p <- pt(t,n-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This  extremely low p-value provides strong evidence against Ho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of how to Use p-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) Choose a test statistic T an decide on the nature of the alternative. This determines whether the rejection rule is t>c, t<-c or |t| >c "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ii) Use the observed value of the t-statistic as the critical value and compute the corresponding significance level of the test. This is the p-value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(iii) If a significance level &alpha; has been chosen, then we reject Ho at the 100&alpha;%level. Therefore, it is a small p-value that leads to rejection of the null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An estimator is a rule for combining data to estimate a population parameter. Two core properties of estimators are unbiadseness and efficiency. Any useful estimator is consistent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The central limit theorem implies that, in large samples, the sampling distribution of most estimators is approximately normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sampling distribution of an estimator can be used to construct confidence intervals. Classical hypotheseis testing, which requires specifying a null hypothesis, an alternative hypopothesis and a significance level, is carried out by comparing a test statistic to a critical value. Alternatively, a p-value can be computed that allows us to carry out a test at any significance level."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
